{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Control for Robotics - Homework 6\n",
    "\n",
    "<p align=\"right\"> 涂志鑫 12131094 </p>\n",
    "<p align=\"right\"> 2022.05 </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Problem 1 \n",
    "$\\textbf{Schur complement lemma}$: Find an equivalent semidefinite condition of the form $G(x) ⪰ 0$ for each of the following statements. Make sure the matrix G(x) you obtained is affine w.r.t. $x$, where $x$ is a vector or matrix variable of appropriate dimension. Please show your steps. \n",
    "\n",
    "(a) (Singular value bound): $σ(A(x)) < β$, where $A$ : $R^n → R^{q×m}$ is affine in x ∈ Rn and σ(·) denotes the singular value of a matrix.\n",
    "\n",
    "(b) (Riccati inequality): $A^Tx+xA+xBR^{−1}B^{T}x+Q ≺ 0$, with $x ∈ S_{++}^n$ , $R ∈ S_{++}^p$ , $Q ∈ S^n$ and $A ∈ R^{n×n}$, and $B ∈ R^{n×p}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution: \n",
    "(a) $\\textbf{(Singular value bound)}$\n",
    "We can know the sigular value of a matrix M is $σ(M) = \\sqrt{eig(M^TM)} .$\n",
    "\n",
    "For the bound of the singular value, $σ(A(x)) < \\beta $ can be expressed by\n",
    "$$ \\begin{aligned}\\sqrt{eig(A(x)^TA(x))} & < \\beta \\\\\n",
    "eig(A(x)^TA(x)) & < \\beta^2 \\\\\n",
    "\\beta^2 - \\mathop{max} {eig(A(x)^TA(x))} & > 0\n",
    "\\end{aligned}$$\n",
    "\n",
    "Therefore, $\\beta^2 I - A(x)^TA(x)$ is PD, For the Schur complement lemma, the inequality can be  \n",
    "\n",
    "$$  \\begin{aligned}\\beta^2 I - A(x)^TA(x) &> 0 \\\\\n",
    " G(x) = \\left[ \\begin{matrix} I & A(x)\\\\ A^T(x) & \\beta^2 I\\end{matrix} \\right] &>0 \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "$$G(x) = \\left[ \\begin{matrix} I & 0\\\\ 0 & \\beta^2 I\\end{matrix} \\right] + \\left[ \\begin{matrix} 0& A(x)\\\\ A^T(x) & 0\\end{matrix} \\right] >0 $$\n",
    "\n",
    "Since $A(x)$ is affine w.r.t x, so $G(x)$ is also affine w.r.t x.\n",
    "\n",
    "\n",
    "(b) $\\textbf{(Riccati inequality)}$   $A^Tx+xA+xBR^{−1}B^{T}x+Q ≺ 0$\n",
    "For  $x ∈ S_{++}^n$ , $R ∈ S_{++}^p$ , $Q ∈ S^n$, $A ∈ R^{n×n}$ and $B ∈ R^{n×p}$.\n",
    "\n",
    "The the inequality can be expressed \n",
    "$$A^Tx+xA+xBR^{−1}B^{T}x+Q = 2xA+Q+xBR^{−1}B^{T}x≺ 0$$\n",
    "$$-(2xA+Q)-xBR^{−1}B^{T}x > 0$$\n",
    "For the Schur complement lemma, the inequality can change to \n",
    "\n",
    "$$ \n",
    "    M = \\left[ \\begin{matrix}R & B^Tx\\\\ xB & -Q-2xA\\end{matrix} \\right] >0\n",
    "    $$\n",
    "\n",
    "$x ∈ S_{++}^n$ can be expressed by \n",
    "$$x = \\sum_i\\sum_{j \\leq i}x_{ij}S_{ij} , S_{ij}\\in S^n$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    M &=\\left[ \\begin{matrix}R & B^Tx\\\\ xB & -Q-2xA\\end{matrix} \\right] \\\\\n",
    "    & = \\left[ \\begin{matrix}R & 0 \\\\ 0 & -Q\\end{matrix} \\right]+ \\sum_i\\sum_{j \\leq i}x_{ij} \\left[ \\begin{matrix}0 & B^TS_{ij}\\\\ S_{ij}B & -2S_{ij}A\\end{matrix} \\right] > 0  \\\\ \n",
    "\\end{aligned} $$\n",
    "\n",
    "For $B ∈ R^{n×p}, S_{ij}\\in S^n$, then $B^TS_{ij} = S_{ij}B$, $\\left[\\begin{matrix}0 & B^TS_{ij}\\\\ S_{ij}B & -2S_{ij}A \\end{matrix}\\right] \\in S^{n+p}$ .\n",
    "\n",
    "Therefore, $ F_0=\\left[ \\begin{matrix}R & 0 \\\\ 0 & -Q\\end{matrix} \\right]$,$ F(x) = \\sum_i\\sum_{j \\leq i}x_{ij} \\left[ \\begin{matrix}0 & B^TS_{ij}\\\\ S_{ij}B & -2S_{ij}A\\end{matrix} \\right] $.\n",
    "\n",
    "$ G(x) = F_0+F(x) >0 $ is affine w.r.t. $x$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2\n",
    "$ \\textbf{Ellipsoid}$ : Ellipsoid in $R^n$ have two equivalent representations: (i) $E_1(P,x_c) = {x ∈ R^n : (x−x_c)P^{−1}(x−x_c) ≤ 1}$ and \n",
    "(ii) $E_2(A, x_c) = {Au+x_c : ∥u∥^2 ≤ 1}$. The second representation can be derived from the first by letting $A = P^{\\frac{1}{2}}$. Given $E_1(P,xc)$ with $P ∈ {S_{++}^n}$, its volume is ${\\nu_n \\sqrt {det(P)}}$ where $\\nu_n$ is the volume of unit ball in ${R^n}$, its semi-axes directions are given by the eigenvectors of $P$ and the lengths of semi-axes are $\\sqrt{λ_i}$, where $\\sqrt{λ_i}$ are eigenvalues of $P$.\n",
    "\n",
    "(a) Given a half space ${x ∈ Rn : a^T x ≤ 1}$. Show that the Ellipsoid $E_2(A, 0)$ is contained in the eigenvectors of $P$ and the lengths of semi-axes are the half space if and only if $a^TAA^Ta ≤ 1$.\n",
    "\n",
    "(b) Note that for any $P ∈ S_{++}^n$, the function $log(det(P))$ is concave in the matrix variable $P$. Formulate a convex optimization problem to find the matrix $P ∈ S_{++}^n$ such that $E_1(P, 0)$ is the largest ellipsoid contained in the polyhedron ${x ∈ R^n : a^T_i x ≤ 1,i = 1,...,m}$\n",
    "\n",
    "(c) Use Drake to solve the above problem with $a^T_1 = [−1, 1]$, $a^T_2 = [2, −1]$, $a^T_3 = [1, 3]$, $a^T_4 = [−2, −5]$. Visualize the polyhedron region and your ellipsoid solution (you can use Matlab for the visualization if you prefer matlab)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution:\n",
    "(a) \n",
    "\n",
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pro2-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3\n",
    "$\\textbf{Stability of Lur’e system}$: Consider a nonlinear system $ \\dot{x} = Ax + b\\phi(t,c^T x)$\n",
    "where $A ∈ R^n×n$, $b ∈ R^n$, $c ∈ R^n$, and for each time $t$, the function $\\phi(t,·) : R→ R$ satisfies sector nonlinearity $|\\phi(t,y)| ≤ α|y|$ for all $y$ (but is otherwise unknown). Such a system represents a very general class of control systems involving time-varying nonlinearities and/or\n",
    "uncertainties, and is often called a Lur’e problem.\n",
    "We would like to find a positive definite Lyapunov function $V (x) = x^T Px$ that satisfies ̇$V (x) ≤ −βV (x)$ for all $x$, and for any function $\\phi$ satisfying the inequality given above. You can assume that $A,b,c,α,β$ are given.\n",
    "\n",
    "(a) Explain how to find such a P (or determine that no such P exists) by expressing the problem as an LMI.\n",
    "\n",
    "(b) Use CVX to construct such a Lyapunov function for the following instance of Lur’e problem:\n",
    "$$A=\\left[\\begin{array}{ccc}\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "-1 & -3 & -3\n",
    "\\end{array}\\right], b=\\left[\\begin{array}{l}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array}\\right] c=\\left[\\begin{array}{l}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{array}\\right], \\alpha=0.7, \\beta=0.1$$\n",
    "\n",
    "#### Solution:\n",
    "(a) For the Lyapunov function $V(x) = x^TPx$, $\\dot{V}(x) = \\dot x^TPx+x^TP\\dot x \\leq -\\beta V(x)$.\n",
    "The nonlinear system is $\\dot x = Ax+b\\phi (t,c^Tx)$, assume $u = b\\phi (t,c^Tx)$, plug in the Lyapunov function, get\n",
    "$$ \\dot V(x) =[Ax+b\\phi (t,c^Tx)]Px+x^TP[Ax+b\\phi (t,c^Tx)] \\leq -\\beta(x^TPx)$$\n",
    "Because the fuction $\\phi(t,·)$ satisfies $|\\phi(t,y)| ≤ α|y|$, the inequality above can be\n",
    "$$  \\begin{aligned}\n",
    "[Ax+u]^TPx+x^TP[Ax+u]+\\beta(x^TPx) &\\leq 0\\\\ \n",
    " x^T(a^TP+PA+\\beta P)x+x^TPu+u^TPx &\\leq 0 \n",
    "\\end{aligned}$$  \n",
    "Change it to the matrix form, for all the $(x,u)$ such that $u = b\\phi(t,c^Tx)$\n",
    "$$\n",
    "\\left[ \\begin{matrix}x^T & u^T \\end{matrix} \\right] \\left[ \\begin{matrix}-(A^TP+PA+\\beta P) & -P\\\\ -P &  0 \\end{matrix} \\right] \\left[ \\begin{matrix}x \\\\ u \\end{matrix} \\right] \\succeq 0 \n",
    "$$ \n",
    "\n",
    "For the function $\\phi(t,·) : R→ R$ satisfies sector nonlinearity $|\\phi(t,y)| ≤ α|y|$, so $||\\phi(t,c^Tx)||^2 \\leq \\alpha^2 (x^Tcc^Tx)$\n",
    "Since $||u||^2 = b^T||\\phi(t,C^Tx)||^2 b \\leq \\alpha^2 b^T (x^Tcc^Tx)b $, that is \n",
    "$$ \\begin{aligned}  u^Tu -\\alpha^2(c^Txb)^T (c^Txb)  &\\leq 0\\\\\n",
    "u^Tu -\\alpha^2x^Tb^Tcc^Tbx  &\\leq 0\\\\\n",
    "\\end{aligned}$$ \n",
    "\n",
    "Change it to matrix form, we can get \n",
    "$$ \\left[ \\begin{matrix}x^T & u^T \\end{matrix} \\right] \\left[ \\begin{matrix} \\alpha^2 cb^Tbc^T  &0\\\\ 0 & -I  \\end{matrix} \\right] \\left[ \\begin{matrix}x \\\\ u \\end{matrix} \\right] \\succeq 0 \n",
    "$$ \n",
    "Assume $G_0 = \\left[ \\begin{matrix}-(A^TP+PA+\\beta P) & -P\\\\ -P &  0 \\end{matrix} \\right]$,$G_1 = \\left[ \\begin{matrix} \\alpha^2 cb^Tbc^T  &0\\\\ 0 & -I  \\end{matrix} \\right]$, by s-procedure, we have $\\exist \\tau>0$, s.t. $G_0>\\tau G_1$, then the problem can be formulated by \n",
    "\n",
    "$$\\left\\{\\begin{array}{ll}\\min _{P,\\tau,\\alpha} & -\\beta \\\\ \\text { subject.: } & P \\succ 0, \\\\& \\tau>0, \\\\ &  G_0-\\tau G_1 \\succeq 0 \\\\\\end{array} \\right.$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<Expression \"( - 0.10000000000000001 * P(0,0) + 2 * P(2,0) - 0.48999999999999994 * tau(0))\">\n",
      "  <Expression \"( - P(0,0) - 0.10000000000000001 * P(1,0) + 3 * P(2,0) + P(2,1))\">\n",
      "  <Expression \"( - P(1,0) + 2.8999999999999999 * P(2,0) + P(2,2))\">\n",
      "  <Expression \"( - P(0,0) - 0.10000000000000001 * P(1,0) + 3 * P(2,0) + P(2,1))\">\n",
      "  <Expression \"( - 2 * P(1,0) - 0.10000000000000001 * P(1,1) + 6 * P(2,1))\">\n",
      "  <Expression \"( - P(2,0) - P(1,1) + 2.8999999999999999 * P(2,1) + 3 * P(2,2))\">]\n",
      " [<Expression \"( - P(1,0) + 2.8999999999999999 * P(2,0) + P(2,2))\">\n",
      "  <Expression \"( - P(2,0) - P(1,1) + 2.8999999999999999 * P(2,1) + 3 * P(2,2))\">\n",
      "  <Expression \"( - 2 * P(2,1) + 5.9000000000000004 * P(2,2))\">\n",
      "  <Expression \"(-1 * P(0,0))\"> <Expression \"(-1 * P(1,0))\">\n",
      "  <Expression \"(-1 * P(2,0))\">]\n",
      " [<Expression \"(-1 * P(1,0))\"> <Expression \"(-1 * P(1,1))\">\n",
      "  <Expression \"(-1 * P(2,1))\"> <Expression \"(-1 * P(2,0))\">\n",
      "  <Expression \"(-1 * P(2,1))\"> <Expression \"(-1 * P(2,2))\">]\n",
      " [<Expression \"(-1 * P(0,0))\"> <Expression \"(-1 * P(1,0))\">\n",
      "  <Expression \"(-1 * P(2,0))\"> <Expression \"(-1 * P(1,0))\">\n",
      "  <Expression \"(-1 * P(1,1))\"> <Expression \"(-1 * P(2,1))\">]\n",
      " [<Expression \"(-1 * P(2,0))\"> <Expression \"(-1 * P(2,1))\">\n",
      "  <Expression \"(-1 * P(2,2))\"> <Expression \"(-1 * tau(0))\">\n",
      "  <Expression \"0\"> <Expression \"0\">]\n",
      " [<Expression \"0\"> <Expression \"(-1 * tau(0))\"> <Expression \"0\">\n",
      "  <Expression \"0\"> <Expression \"0\"> <Expression \"(-1 * tau(0))\">]]\n",
      "no result\n"
     ]
    }
   ],
   "source": [
    "# pro3-2\n",
    "import numpy as np\n",
    "from pydrake.all import (MathematicalProgram, Solve)\n",
    "# This code is mainly adapted from Russ Tedrake. Underactuated Robotics: Algorithms for Walking,\n",
    "#  Running, Swimming, Flying, and Manipulation (Course Notes for MIT 6.832). Downloaded from http://underactuated.mit.edu/\n",
    "\n",
    "\n",
    "A = np.mat([[0, 1, 0], [0, 0, 1], [-1, -3, -3]])\n",
    "\n",
    "b = np.array([[0], [0], [1]])\n",
    "c = np.array([[1], [0], [0]])\n",
    "alpha = 0.7\n",
    "beta = 0.1\n",
    "\n",
    "# Step 2: formulate the S.D.P.\n",
    "prog = MathematicalProgram()\n",
    "num_states = 3\n",
    "P = prog.NewSymmetricContinuousVariables(num_states, \"P\")\n",
    "tau = prog.NewContinuousVariables(1, \"tau\")\n",
    "\n",
    "I = np.identity(3)\n",
    "G =[-(A.T@P+P@A+beta*P+tau*alpha**2*c@b.T@b@c.T),-P],[-P,-tau*I]\n",
    "G = np.array(G).reshape(6,6)\n",
    "print(G)\n",
    "# find P,tau\n",
    "\n",
    "#prog.AddLinearCost(np.trace(X))\n",
    "\n",
    "# s.t.\n",
    "prog.AddPositiveSemidefiniteConstraint(P - .01 *np.identity(num_states))\n",
    "\n",
    "prog.AddPositiveSemidefiniteConstraint(G)\n",
    "    \n",
    "\n",
    "result = Solve(prog)\n",
    "\n",
    "if result.is_success():\n",
    "    P = result.GetSolution(P)\n",
    "    tau = result.GetSolution(tau)\n",
    "    print(\"Succeed to find the solution! \")\n",
    "    print(\"P = \\n\", P)\n",
    "    print(\"tau = \\n \", tau)\n",
    "else:\n",
    "    print(\"no result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Problem 4\n",
    "$\\textbf{Stabilization via LMIs}$: Consider the time-varying LDS (linear dynamical system) $$\\dot{x}(t) = A(t)x(t) + Bu(t),$$\n",
    "with $x(t) ∈ R^n$ and $u(t) ∈ R^m$, where $A(t) ∈ {A_1, . . . , A_M }$. Thus, the dynamics matrix $A(t)$ can take any of $M$ values, at any time. We seek a linear state feedback gain matrix K ∈ Rm×n for which the closed-loop system\n",
    "$$\\dot{x}(t) = [A(t) + BK]x(t),$$\n",
    "is globally asymptotically stable. But even if you are given a specific state feedback gain matrix $K$, this is very hard to determine. So we will require the existence of a quadratic Lyapunov function that establishes exponential stability of the closed-loop system, i.e., a matrix $P=PT ≻0$ for which\n",
    "$$\\dot{V}(z, t) = z^T [(A(t) + BK)^T P + P (A(t) + BK)]z ≤ −βV (z)$$\n",
    "for all $z$, and for any possible value of $A(t)$. (The parameter $β > 0$ is given, and sets a minimum decay rate for the closed-loop trajectories.) \n",
    "So roughly speaking we seek\n",
    "\n",
    "* a stabilizing state feedback gain, and\n",
    "* a quadratic Lyapunov function that certifies the closed-loop performance.\n",
    "  \n",
    "In this problem, you will use LMIs to find both $K$ and $P$, simultaneously.\n",
    "\n",
    "(a) Pose the problem of finding P and K as an LMI problem. \n",
    "Hint: Starting from the inequality above, you will not get an LMI in the variables $P$ and $K$ (although you will have a set of matrix inequalities that are affine in $K$, for fixed $P$, and linear in $P$, for fixed $K$). Use the new variables $X = P^{−1}$ and $Y = KP^{−1}$. Be sure to explain why you can change variables.\n",
    "\n",
    "(b) Carry out your method for the specific problem instance\n",
    "$$\n",
    "A_{1}=\\left[\\begin{array}{ccc}\n",
    "-0.5 & 0.3 & 0.4 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{array}\\right], \\quad A_{2}=\\left[\\begin{array}{ccc}\n",
    "-0.7 & 0.1 & -0.2 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{array}\\right], \\quad A_{3}=\\left[\\begin{array}{ccc}\n",
    "0.6 & -0.7 & 0.2 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "$B=(1,0,0)$, and $\\beta=1$. (Thus, we require a closed-loop decay at least as fast as $e^{-t / 2}$.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "(a) For the time varying linear system, asymptotically stable is equivalent to exponential stable. For the Lyapunov function $V(z,t) = z^TPz$, the condition for stable is \n",
    "$$ P >0$$\n",
    "$$ \\dot{V}(z,t) = z^T [(A(t) + BK)^T P + P (A(t) + BK)]z ≤ −βV (z)$$\n",
    "\n",
    "For the second conditon we can get\n",
    "$$ z^T [(A(t) + BK)^T P + P (A(t) + BK) + \\beta P]z ≤ 0$$\n",
    "\n",
    "Define $X = P^{-1},Y = KP^{-1}$, $P$ is symmetric matrix $P = P^T$, multiply $P^{-1}$ to the both sides of the inequality, then the above inequality can be\n",
    "$$ XA(t)^T+Y^TB^T+A(t)X+BY+\\beta X \\leq 0 \\\\ \n",
    " A(t)X + (A(t)X)^T + BY +(BY)^T + \\beta X \\leq 0  \\\\\n",
    " -(A(t)X + (A(t)X)^T + BY +(BY)^T + \\beta X) \\geq 0 .$$\n",
    "\n",
    " In order to get a minimum decay rate for the clossed-loop trajectories, we must get $\\beta$ maximum, so the problem can be formulated by \n",
    "\n",
    "$$\\left\\{\\begin{array}{ll}\\min _{X,Y} & -\\beta \\\\ \\text { subject.: } & X^{-1} \\succ 0, \\\\ &  -(A(t)X + (A(t)X)^T + BY +(BY)^T + \\beta X) \\succeq 0 \\\\\\end{array} \\right.$$\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed to find the result! \n",
      "P = \n",
      " [[ 0.22333181 -0.14411104 -0.1899522 ]\n",
      " [-0.14411104  0.13834869  0.09730774]\n",
      " [-0.1899522   0.09730774  0.19301234]]\n",
      "K = \n",
      "  [-21.91386075  14.14052611  18.63857253]\n"
     ]
    }
   ],
   "source": [
    "# pro4-2\n",
    "import numpy as np\n",
    "from pydrake.all import (MathematicalProgram, Solve)\n",
    "# This code is mainly adapted from Russ Tedrake. Underactuated Robotics: Algorithms for Walking,\n",
    "#  Running, Swimming, Flying, and Manipulation (Course Notes for MIT 6.832). Downloaded from http://underactuated.mit.edu/\n",
    "\n",
    "# Problem 4(b)\n",
    "# Step 1: define dynamics matrices A_i(t) and corresponding parameters\n",
    "A = []\n",
    "A.append(np.mat([[-0.5, 0.3, 0.4], [1, 0, 0], [0, 1, 0]]))\n",
    "A.append(np.mat([[-0.7, 0.1, -0.2], [1, 0, 0], [0, 1, 0]]))\n",
    "A.append(np.mat([[0.6, -0.7, 0.2], [1, 0, 0], [0, 1, 0]]))\n",
    "\n",
    "# B = np.mat([[1], [0], [0]])\n",
    "B = np.array([1, 0, 0])\n",
    "beta = 1.0\n",
    "\n",
    "# Step 2: formulate the S.D.P.\n",
    "prog = MathematicalProgram()\n",
    "num_states = 3\n",
    "X = prog.NewSymmetricContinuousVariables(num_states, \"X\")\n",
    "Y = prog.NewContinuousVariables(num_states, \"Y\")\n",
    "\n",
    "# find X,Y\n",
    "\n",
    "#prog.AddLinearCost(np.trace(X))\n",
    "\n",
    "# s.t.\n",
    "prog.AddPositiveSemidefiniteConstraint(X - .01 * np.identity(num_states))\n",
    "for i in range(len(A)):\n",
    "    prog.AddPositiveSemidefiniteConstraint(\n",
    "        -(X.dot(A[i].transpose()) + Y.transpose().dot(B.transpose()) + A[i].dot(X) + B.dot(Y) + beta * X - .1 * np.identity(num_states))\n",
    "    )\n",
    "\n",
    "result = Solve(prog)\n",
    "\n",
    "if result.is_success():\n",
    "    X = result.GetSolution(X)\n",
    "    Y = result.GetSolution(Y)\n",
    "    P = np.linalg.inv(X)\n",
    "    K = Y.dot(P) \n",
    "    print(\"Succeed to find the solution! \")\n",
    "    print(\"P = \\n\", P)\n",
    "    print(\"K = \\n \", K)\n",
    "else:\n",
    "    print(\"no result\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5\n",
    "$\\textbf{Derivation of Dual SDP}$ (Optional; will not be graded): Consider the prime and dual SDP problems discussed in class. \n",
    "\n",
    "$(\\mathbf{P S D P}):\\left\\{\\begin{array}{ll}\\min _{X} & C \\bullet X \\\\ \\text { subj.: } & A_{i} \\bullet X=b_{i}, \\\\ & i=1, \\ldots, m \\\\ & X \\succeq 0\\end{array} \\quad(\\mathbf{D S D P}): \\begin{cases}\\max _{y \\in \\mathbb{R}^{m}} & b^{T} y \\\\ \\operatorname{subj} .: & \\sum_{i=1}^{m} y_{i} A_{i} \\preceq C\\end{cases}\\right.$\n",
    "\n",
    "This homework problem intends to guide you through the derivation of the dual SDP problem. We need to introduce a few definitions. In general, the Lagrangian dual of a constrained optimization problem $\\min _{x \\in \\mathcal{X}}\\{f(x): h(x)=0\\}$ is defined as\n",
    "$$\n",
    "\\max _{y \\in \\mathbb{R}^{m}}\\left(\\min _{x \\in \\mathcal{X}}\\left\\{f(x)+y^{T} h(x)\\right\\}\\right)\n",
    "$$\n",
    "To derive the desired dual form, we also need a concept: dual cone. Let $\\mathcal{V}$ be an inner product space. Suppose $K \\subseteq \\mathcal{V}$ is a cone, i.e., $\\lambda x \\in \\mathcal{K}$ for all $x \\in \\mathcal{K}$. The dual cone of $K$ is defined as\n",
    "$$\n",
    "\\operatorname{Dual}(K)=\\{z \\in \\mathcal{V}:\\langle z, x\\rangle \\geq 0, \\forall x \\in \\mathcal{K}\\}\n",
    "$$\n",
    "The dual of the PSD cone is thus dual $\\left(\\mathcal{S}_{+}^{n}\\right)=\\left\\{Y \\in \\mathcal{S}^{n}: Y \\bullet X \\geq 0, \\forall X \\in \\mathcal{S}_{+}^{n}\\right\\}$. A well-known fact about PSD cone is that it is self-dual, i.e. $\\mathcal{S}_{+}^{n}=\\operatorname{dual}\\left(\\mathcal{S}_{+}^{n}\\right)$.\n",
    "\n",
    "(a) Write down the Lagrangian dual problem for (PSDP).\n",
    "\n",
    "(b) Show that $\\min _{X \\succeq 0}\\langle Y, X\\rangle=\\left\\{\\begin{array}{ll}0 & \\text { if } Y \\succeq 0 \\\\ -\\infty & \\text { otherwise }\\end{array}\\right.$ (Hint: use the fact that $\\mathcal{S}_{+}^{n}$ is acute and self-dual.\n",
    "\n",
    "(c) Show that the Lagrangian dual problem of (PSDP) can be reduced to the form (DSDP) given above. \n",
    "\n",
    "#### Solution\n",
    "(a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51109f29b74c83a02380174f2a388167f95e9702dac943105d59ff44b41a3852"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
