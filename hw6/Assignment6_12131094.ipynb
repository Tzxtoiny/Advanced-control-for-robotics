{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Control for Robotics - Homework 6\n",
    "\n",
    "<p align=\"right\"> 涂志鑫 12131094 </p>\n",
    "<p align=\"right\"> 2022.05 </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Problem 1 \n",
    "$\\textbf{Schur complement lemma}$: Find an equivalent semidefinite condition of the form $G(x) ⪰ 0$ for each of the following statements. Make sure the matrix G(x) you obtained is affine w.r.t. $x$, where $x$ is a vector or matrix variable of appropriate dimension. Please show your steps.\n",
    "(a) (Singular value bound): $σ(A(x)) < β$, where $A$ : $Rn → R^{q×m}$ is affine in x ∈ Rn and σ(·) denotes the singular value of a matrix.\n",
    "(b) (Riccati inequality): $A^Tx+xA+xBR^{−1}B^{T}x+Q ≺ 0$, with $x ∈ Sn$ , $R ∈ Sp$ , $Q ∈ Sn$\n",
    "and $A ∈ R^{n×n}$, and $B ∈ R^{n×p}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution: \n",
    "(a) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2\n",
    "$ \\textbf{Ellipsoid}$ : Ellipsoid in $R^n$ have two equivalent representations: (i) $E_1(P,x_c) = {x ∈ R^n : (x−x_c)P −1(x−x_c) ≤ 1}$ and \n",
    "(ii) $E_2(A, x_c) = {Au+x_c : ∥u∥^2 ≤ 1}$. The second representation can be derived from the first by letting $A = P^{\\frac{1}{2}}$. Given $E_1(P,xc)$ with $P ∈ {S_{++}^n}$, its volume is ${\\nu_n \\sqrt {det(P)}}$ where $\\nu_n$ is the volume of unit ball in ${R^n}$, its semi-axes directions are given by the eigenvectors of $P$ and the lengths of semi-axes are $\\sqrt{λ_i}$, where $\\sqrt{λ_i}$ are eigenvalues of $P$.\n",
    "\n",
    "(a) Given a half space {x ∈ Rn : aT x ≤ 1}. Show that the Ellipsoid E2(A, 0) is contained in the eigenvectors of P and the lengths of semi-axes are the half space if and only if $a^TAA^Ta ≤ 1$.\n",
    "\n",
    "(b) Note that for any $P ∈ S_{++}^n$, the function $log(det(P))$ is concave in the matrix variable $P$. Formulate a convex optimization problem to find the matrix $P ∈ S_{++}^n$ such that $E_1(P, 0)$ is the largest ellipsoid contained in the polyhedron ${x ∈ R^n : a^T_i x ≤ 1,i = 1,...,m}$\n",
    "\n",
    "(c) Use Drake to solve the above problem with $a^T_1 = [−1, 1]$, $a^T_2 = [2, −1]$, $a^T_3 = [1, 3]$, $a^T_4 = [−2, −5]$. Visualize the polyhedron region and your ellipsoid solution (you can use Matlab for the visualization if you prefer matlab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution:\n",
    "(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3\n",
    "$\\textbf{Stability of Lur’e system}$: Consider a nonlinear system $ \\dot{x} = Ax + b\\phi(t,c^T x)$\n",
    "where $A ∈ R^n×n$, $b ∈ R^n$, $c ∈ R^n$, and for each time $t$, the function $\\phi(t,·) : R→ R$ satisfies sector nonlinearity $|\\phi(t,y)| ≤ α|y|$ for all $y$ (but is otherwise unknown). Such a system represents a very general class of control systems involving time-varying nonlinearities and/or\n",
    "uncertainties, and is often called a Lur’e problem.\n",
    "We would like to find a positive definite Lyapunov function $V (x) = x^T Px$ that satisfies ̇$V (x) ≤ −βV (x)$ for all $x$, and for any function $\\phi$ satisfying the inequality given above. You can assume that $A,b,c,α,β$ are given.\n",
    "(a) Explain how to find such a P (or determine that no such P exists) by expressing the problem as an LMI.\n",
    "\n",
    "(b) Use CVX to construct such a Lyapunov function for the following instance of Lur’e problem:\n",
    "$$A=\\left[\\begin{array}{ccc}\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "-1 & -3 & -3\n",
    "\\end{array}\\right], b=\\left[\\begin{array}{l}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array}\\right] c=\\left[\\begin{array}{l}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{array}\\right], \\alpha=0.7, \\beta=0.1$$\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Problem 4\n",
    "$\\textbf{Stabilization via LMIs}$: Consider the time-varying LDS (linear dynamical system) $$\\dot{x}(t) = A(t)x(t) + Bu(t),$$\n",
    "with $x(t) ∈ R^n$ and $u(t) ∈ R^m$, where $A(t) ∈ {A_1, . . . , A_M }$. Thus, the dynamics matrix $A(t)$ can take any of $M$ values, at any time. We seek a linear state feedback gain matrix K ∈ Rm×n for which the closed-loop system\n",
    "$$\\dot{x}(t) = [A(t) + BK]x(t),$$\n",
    "is globally asymptotically stable. But even if you are given a specific state feedback gain matrix $K$, this is very hard to determine. So we will require the existence of a quadratic Lyapunov function that establishes exponential stability of the closed-loop system, i.e., a matrix $P=PT ≻0$ for which\n",
    "$$\\dot{V}(z, t) = z^T [(A(t) + BK)^T P + P (A(t) + BK)]z ≤ −βV (z)$$\n",
    "for all $z$, and for any possible value of $A(t)$. (The parameter $β > 0$ is given, and sets a minimum decay rate for the closed-loop trajectories.) \n",
    "So roughly speaking we seek\n",
    "\n",
    "* a stabilizing state feedback gain, and\n",
    "* a quadratic Lyapunov function that certifies the closed-loop performance.\n",
    "  \n",
    "In this problem, you will use LMIs to find both $K$ and $P$, simultaneously.\n",
    "\n",
    "(a) Pose the problem of finding P and K as an LMI problem. \n",
    "Hint: Starting from the inequality above, you will not get an LMI in the variables $P$ and $K$ (although you will have a set of matrix inequalities that are affine in $K$, for fixed $P$, and linear in $P$, for fixed $K$). Use the new variables $X = P−1$ and $Y = KP−1$. Be sure to explain why you can change variables.\n",
    "\n",
    "(b) Carry out your method for the specific problem instance\n",
    "$$\n",
    "A_{1}=\\left[\\begin{array}{ccc}\n",
    "-0.5 & 0.3 & 0.4 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{array}\\right], \\quad A_{2}=\\left[\\begin{array}{ccc}\n",
    "-0.7 & 0.1 & -0.2 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{array}\\right], \\quad A_{3}=\\left[\\begin{array}{ccc}\n",
    "0.6 & -0.7 & 0.2 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "$B=(1,0,0)$, and $\\beta=1$. (Thus, we require a closed-loop decay at least as fast as $e^{-t / 2}$.)\n",
    "\n",
    "#### Solution\n",
    "(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5\n",
    "$\\textbf{Derivation of Dual SDP}$ (Optional; will not be graded): Consider the prime and dual SDP problems discussed in class. \n",
    "\n",
    "$(\\mathbf{P S D P}):\\left\\{\\begin{array}{ll}\\min _{X} & C \\bullet X \\\\ \\text { subj.: } & A_{i} \\bullet X=b_{i}, \\\\ & i=1, \\ldots, m \\\\ & X \\succeq 0\\end{array} \\quad(\\mathbf{D S D P}): \\begin{cases}\\max _{y \\in \\mathbb{R}^{m}} & b^{T} y \\\\ \\operatorname{subj} .: & \\sum_{i=1}^{m} y_{i} A_{i} \\preceq C\\end{cases}\\right.$\n",
    "\n",
    "This homework problem intends to guide you through the derivation of the dual SDP problem. We need to introduce a few definitions. In general, the Lagrangian dual of a constrained optimization problem $\\min _{x \\in \\mathcal{X}}\\{f(x): h(x)=0\\}$ is defined as\n",
    "$$\n",
    "\\max _{y \\in \\mathbb{R}^{m}}\\left(\\min _{x \\in \\mathcal{X}}\\left\\{f(x)+y^{T} h(x)\\right\\}\\right)\n",
    "$$\n",
    "To derive the desired dual form, we also need a concept: dual cone. Let $\\mathcal{V}$ be an inner product space. Suppose $K \\subseteq \\mathcal{V}$ is a cone, i.e., $\\lambda x \\in \\mathcal{K}$ for all $x \\in \\mathcal{K}$. The dual cone of $K$ is defined as\n",
    "$$\n",
    "\\operatorname{Dual}(K)=\\{z \\in \\mathcal{V}:\\langle z, x\\rangle \\geq 0, \\forall x \\in \\mathcal{K}\\}\n",
    "$$\n",
    "The dual of the PSD cone is thus dual $\\left(\\mathcal{S}_{+}^{n}\\right)=\\left\\{Y \\in \\mathcal{S}^{n}: Y \\bullet X \\geq 0, \\forall X \\in \\mathcal{S}_{+}^{n}\\right\\}$. A well-known fact about PSD cone is that it is self-dual, i.e. $\\mathcal{S}_{+}^{n}=\\operatorname{dual}\\left(\\mathcal{S}_{+}^{n}\\right)$.\n",
    "\n",
    "(a) Write down the Lagrangian dual problem for (PSDP).\n",
    "\n",
    "(b) Show that $\\min _{X \\succeq 0}\\langle Y, X\\rangle=\\left\\{\\begin{array}{ll}0 & \\text { if } Y \\succeq 0 \\\\ -\\infty & \\text { otherwise }\\end{array}\\right.$ (Hint: use the fact that $\\mathcal{S}_{+}^{n}$ is acute and self-dual.\n",
    "\n",
    "(c) Show that the Lagrangian dual problem of (PSDP) can be reduced to the form (DSDP) given above. \n",
    "\n",
    "#### Solution\n",
    "(a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "PyCharm (Advanced-control-for-robotics)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
